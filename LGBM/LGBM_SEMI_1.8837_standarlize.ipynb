{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LGBM_SEMI_1.8837_standarlize.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"wdGwa4LNi_DX"},"source":["\r\n","\r\n","*   변수\r\n","*   항목 추가\r\n","\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OLGN3Uo0KgsL","outputId":"19b241ee-80af-4d0c-d34b-b8a05f684dc6"},"source":["!git clone --recursive https://github.com/Microsoft/LightGBM\r\n","! cd LightGBM && rm -rf build && mkdir build && cd build && cmake -DUSE_GPU=1 ../../LightGBM && make -j4 && cd ../python-package && python3 setup.py install --precompile --gpu;"],"execution_count":null,"outputs":[{"output_type":"stream","text":["fatal: destination path 'LightGBM' already exists and is not an empty directory.\n","-- The C compiler identification is GNU 7.5.0\n","-- The CXX compiler identification is GNU 7.5.0\n","-- Check for working C compiler: /usr/bin/cc\n","-- Check for working C compiler: /usr/bin/cc -- works\n","-- Detecting C compiler ABI info\n","-- Detecting C compiler ABI info - done\n","-- Detecting C compile features\n","-- Detecting C compile features - done\n","-- Check for working CXX compiler: /usr/bin/c++\n","-- Check for working CXX compiler: /usr/bin/c++ -- works\n","-- Detecting CXX compiler ABI info\n","-- Detecting CXX compiler ABI info - done\n","-- Detecting CXX compile features\n","-- Detecting CXX compile features - done\n","-- Found OpenMP_C: -fopenmp (found version \"4.5\") \n","-- Found OpenMP_CXX: -fopenmp (found version \"4.5\") \n","-- Found OpenMP: TRUE (found version \"4.5\")  \n","-- Looking for CL_VERSION_2_2\n","-- Looking for CL_VERSION_2_2 - found\n","-- Found OpenCL: /usr/lib/x86_64-linux-gnu/libOpenCL.so (found version \"2.2\") \n","-- OpenCL include directory: /usr/include\n","-- Boost version: 1.65.1\n","-- Found the following Boost libraries:\n","--   filesystem\n","--   system\n","-- Performing Test MM_PREFETCH\n","-- Performing Test MM_PREFETCH - Success\n","-- Using _mm_prefetch\n","-- Performing Test MM_MALLOC\n","-- Performing Test MM_MALLOC - Success\n","-- Using _mm_malloc\n","-- Configuring done\n","-- Generating done\n","-- Build files have been written to: /content/LightGBM/build\n","\u001b[35m\u001b[1mScanning dependencies of target _lightgbm\u001b[0m\n","\u001b[35m\u001b[1mScanning dependencies of target lightgbm\u001b[0m\n","[  1%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/boosting.cpp.o\u001b[0m\n","[  2%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/main.cpp.o\u001b[0m\n","[  4%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt.cpp.o\u001b[0m\n","[  5%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/application/application.cpp.o\u001b[0m\n","[  7%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt_model_text.cpp.o\u001b[0m\n","[  8%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/boosting.cpp.o\u001b[0m\n","[ 10%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt_prediction.cpp.o\u001b[0m\n","[ 11%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/prediction_early_stop.cpp.o\u001b[0m\n","[ 13%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/bin.cpp.o\u001b[0m\n","[ 14%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/config.cpp.o\u001b[0m\n","[ 15%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt.cpp.o\u001b[0m\n","[ 17%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/config_auto.cpp.o\u001b[0m\n","[ 18%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt_model_text.cpp.o\u001b[0m\n","[ 20%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt_prediction.cpp.o\u001b[0m\n","[ 21%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/dataset.cpp.o\u001b[0m\n","[ 23%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/prediction_early_stop.cpp.o\u001b[0m\n","[ 24%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/bin.cpp.o\u001b[0m\n","[ 26%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/config.cpp.o\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tanM9U9j7xax"},"source":["import pandas as pd\r\n","import numpy as np\r\n","import seaborn as sns\r\n","import matplotlib.pyplot as plt\r\n","from pandas import DataFrame, concat\r\n","!pip install import_ipynb\r\n","import import_ipynb\r\n","from google.colab import drive\r\n","drive.mount('/content/drive')\r\n","from datetime import date\r\n","import lightgbm as lgbm\r\n","from lightgbm import LGBMRegressor\r\n","import time\r\n","import statsmodels.api as sm\r\n","from sklearn import linear_model, metrics\r\n","from sklearn.model_selection import train_test_split\r\n","from tqdm import tnrange, tqdm_notebook\r\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\r\n","from statsmodels.regression.quantile_regression import QuantReg\r\n","from sklearn.ensemble import GradientBoostingRegressor\r\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4SzsiaLqCrZO"},"source":["import math\r\n","from math import radians\r\n","from sklearn.preprocessing import StandardScaler\r\n","from sklearn.preprocessing import MinMaxScaler"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pVYbSp4X7_Qq"},"source":["#### 파라미터 ####\r\n","\r\n","# 하루의 틱\r\n","ticks = 48\r\n","\r\n","# 예측에 사용할 일수\r\n","days = 3                # 이 부분을 바꿀 수 있다.\r\n","n_days = ticks*days\r\n","\r\n","# 미래 예측할 일수\r\n","future_days = 2\r\n","future_window = ticks * future_days\r\n","\r\n","### 모든변수\r\n","# ['Hour', 'Minute', 'Day', 'WS', 'Time', 'DHI','DNI','RH','T','TARGET']\r\n","\r\n","# 사용할 변수\r\n","what_to_left = ['Time', 'WS', 'DHI','DNI','RH','T','TARGET', 'Day']\r\n","\r\n","n_features = len(what_to_left)\r\n","n_obs = n_days * n_features # 7일 예측 기준으로 7(일 수) * 48(틱 수) * 6(변수 개수)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ppzWBSoP8AYz"},"source":["# 데이터 불러오기 \r\n","\r\n","raw_data = pd.read_csv('/content/drive/MyDrive/Jupyter/unlimited_power/raw_data/train/train.csv')\r\n","submission = pd.read_csv('/content/drive/MyDrive/Jupyter/unlimited_power/raw_data/sample_submission.csv')\r\n","submission.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IElz-CCj8CfJ"},"source":["def drop_clms(dataset):\r\n","  dataset['Time'] = dataset['Hour'] + dataset['Minute']*(0.5/30)\r\n","  dataset['Date'] = dataset['Day']%365\r\n","  dataset.drop('Day', axis=1, inplace=True)\r\n","  \r\n","  temp = list()\r\n","  for i in range(0, len(dataset), 48):\r\n","    temp += [24-(list(dataset.DHI[i:i+48]).count(0)*0.5)]*48 \r\n","\r\n","  dataset[\"SH\"] = temp\r\n","\r\n","  return dataset\r\n","\r\n","def cos_time(dataset):\r\n","  dataset['sin_time'] = np.sin(2*np.pi*dataset.Time/24)\r\n","  dataset['cos_time'] = np.cos(2*np.pi*dataset.Time/24)\r\n","  return dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S5MqRQyG8Ssv"},"source":["def get_yday(when):\r\n","  HP = date(2020,1,1)\r\n","  results = (when-HP).days\r\n","  return results"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CmXuz7BE8TxK"},"source":["def 절기24(Date):\r\n","  target = 0\r\n","  for i in list24:\r\n","    if Date < i:\r\n","      target = list24.index(i) - 1\r\n","      break\r\n","  if Date < 5:\r\n","    target = 23\r\n","  return target"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fnURqcW48V8S"},"source":["# 머신러닝에 쓰기 위해서 재정렬 시키는 series_to_supervised 함수\r\n","\r\n","def train_to_supervised(train, target, n_in):\r\n","\r\n","    clmns = list(train.columns)\r\n","\r\n","    # 기타 칼럼은 전과 같이 들어갈 것.\r\n","    scaled_lst = clmns\r\n","\r\n","    scaled_df = train[scaled_lst]\r\n","    target_df = target\r\n","\r\n","    # 미래 몇 번째 항목을 가져올 것인가\r\n","    future = [48, 96]\r\n","\r\n","    ### 만약에 스케일링을 하고 싶다면 ###\r\n","    # scaled_df 데이터 프레임만 스케일링 하고, 절기랑 TARGET 데이터는 그냥 두면 된다.\r\n","\r\n","    # 스케일링 해도 되고, 안해도 되는 기존에 썻던 변수들 전처리\r\n","    cols, names = list(), list()\r\n","    n_vars = 1 if type(scaled_df) is list else scaled_df.shape[1]\r\n","    n_vars2 = 1 if type(target_df) is list else target_df.shape[1]\r\n","    for i in range(n_in, 0, -1):\r\n","        cols.append(scaled_df.shift(i))\r\n","        names += [('%s(t-%d)' % (j, i)) for j in scaled_df.columns]\r\n","\r\n","    # 48과 96 후의 타겟 데이터 2개 붙이기.\r\n","    # forecast sequence (t, t+1, ... t+n)\r\n","    for i in future:\r\n","        cols.append(target_df.shift(-i))\r\n","        if i == 0:\r\n","            names += [('TARGET%d(t)' % (j+1)) for j in range(n_vars2)]\r\n","        else:\r\n","            names += [('TARGET%d(t+%d)' % (j+1, i)) for j in range(n_vars2)]\r\n","    # put it all together\r\n","    agg = concat(cols, axis=1)\r\n","    agg.columns = names\r\n","    # drop rows with NaN values\r\n","    agg.dropna(inplace=True)\r\n","    return agg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cJh6MAlFAHwR"},"source":["# 머신러닝에 쓰기 위해서 재정렬 시키는 series_to_supervised 함수\r\n","\r\n","def test_to_supervised(train, n_in):\r\n","\r\n","    clmns = list(train.columns)\r\n","\r\n","    # 타켓 칼럼의 이름을 여기에 입력\r\n","    target = ['TARGET']\r\n","\r\n","    # 클래스 변수로 전환(encoding)할 칼럼을 여기에 입력\r\n","#    class_lst = ['season']\r\n","\r\n","    # 기타 칼럼은 전과 같이 들어갈 것.\r\n","#    scaled_lst = list(set(clmns) - set(class_lst))\r\n","\r\n","    scaled_df = train.copy()\r\n","#    class_df = train[class_lst]\r\n","\r\n","    ### 만약에 스케일링을 하고 싶다면 ###\r\n","    # testset의 스케일링은 구조가 상당히 까다로우므로....... 일단 나중에 하기로 함.\r\n","\r\n","    # 스케일링 해도 되고, 안해도 되는 기존에 썻던 변수들 전처리\r\n","    cols, names = list(), list()\r\n","    n_vars = 1 if type(scaled_df) is list else scaled_df.shape[1]\r\n","    for i in range(n_in, 0, -1):\r\n","        cols.append(scaled_df.shift(i))\r\n","        names += [('%s(t-%d)' % (j, i)) for j in scaled_df.columns]\r\n","\r\n","    # class라 encoding 필요한 절기 끝에 하나만 붙여놓기\r\n","#    cols.append(class_df)\r\n","#    names += class_lst\r\n","    \r\n","    # put it all together\r\n","    agg = concat(cols, axis=1)\r\n","    agg.columns = names\r\n","    # drop rows with NaN values\r\n","    agg.dropna(inplace=True)\r\n","    return agg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ODgWtxW18Wlp"},"source":["소한 = get_yday(date(2020,1,6))\r\n","대한 = get_yday(date(2020,1,20))\r\n","입춘 = get_yday(date(2020,2,4))\r\n","우수 = get_yday(date(2020,2,19))\r\n","경칩 = get_yday(date(2020,3,6))\r\n","춘분 = get_yday(date(2020,3,21))\r\n","청명 = get_yday(date(2020,4,5))\r\n","곡우 = get_yday(date(2020,4,20))\r\n","입하 = get_yday(date(2020,5,6))\r\n","소만 = get_yday(date(2020,5,21))\r\n","망종 = get_yday(date(2020,6,6))\r\n","하지 = get_yday(date(2020,6,22))\r\n","소서 = get_yday(date(2020,7,7))\r\n","대서 = get_yday(date(2020,7,23))\r\n","입추 = get_yday(date(2020,8,8))\r\n","처서 = get_yday(date(2020,8,23))\r\n","백로 = get_yday(date(2020,9,8))\r\n","추분 = get_yday(date(2020,9,23))\r\n","한로 = get_yday(date(2020,10,8))\r\n","상강 = get_yday(date(2020,10,24))\r\n","입동 = get_yday(date(2020,11,8))\r\n","소설 = get_yday(date(2020,11,22))\r\n","대설 = get_yday(date(2020,12,7))\r\n","동지 = get_yday(date(2020,12,22))\r\n","\r\n","list24 = [소한, 대한, 입춘, 우수, 경칩, 춘분, 청명, 곡우, 입하, 소만, 망종, 하지, 소서, 대서, 입추, 처서, 백로, 추분, 한로, 상강, 입동, 소설, 대설, 동지]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4qDBgXyL9HPR"},"source":["m = 60\r\n","\r\n","일출 = [7+47/m, 7+44/m, 7+34/m, 7+18/m, 6+56/m, 6+35/m, 6+12/m, 5+51/m, 5+33/m, 5+19/m, 5+11/m, 5+11/m, 5+17/m, 5+27/m, 5+41/m, 5+54/m, 6+8/m, 6+20/m, 6+33/m, 6+47/m, 7+3/m, 7+20/m, 7+33/m, 7+45/m]\r\n","일몰 = [17+28/m, 17+42/m, 17+58/m, 18+15/m, 18+30/m, 18+44/m, 18+58/m, 19+12/m, 19+25/m, 19+39/m, 19+50/m, 19+57/m, 19+56/m, 19+50/m, 19+35/m, 19+15/m, 18+51/m, 18+28/m, 18+6/m, 17+45/m, 17+28/m, 17+17/m, 17+13/m, 17+17/m]\r\n","경사각 = [32.92, 36.83, 40.75, 44.67, 48.58, 52.5, 56.42, 60.33, 64.25, 68.16, 72.01, 76, 72.1, 68.16, 64.25, 60.33, 56.42, 52.5, 48.58, 44.67, 40.75, 36.83, 32.92, 29]\r\n","남중 = [12+36/m, 12+41/m, 12+44/m, 12+44/m, 12+42/m, 12+38/m, 12+34/m, 12+29/m, 12+27/m, 12+27/m, 12+29/m, 12+32/m, 12+35/m, 12+37/m, 12+36/m, 12+33/m, 12+29/m, 12+23/m, 12+18/m, 12+15/m, 12+14/m, 12+16/m, 12+22/m, 12+29/m]\r\n","print(len(일출), len(일몰), len(경사각), len(남중))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"56dK3l3i-c6z"},"source":["def HRA(DHI, DNI, season, hour):\r\n","  # 위도(latitude) 기준을 일단 임의로 대전으로 설정 (위도 36.19~36.2도)\r\n","  latitude = radians(36.2)\r\n","  season = int(season)\r\n","  # 절기별 대한민국의 경사각\r\n","  tilt = radians(경사각[season])\r\n","\r\n","  # 절기별 대한민국 대전의 태양 남중시각\r\n","  hra = radians(15*(hour - 남중[season]))\r\n","\r\n","  # 구하려는 알파\r\n","  elevation = np.arcsin(np.sin(tilt) * np.sin(latitude) + np.cos(tilt) * np.cos(latitude) * np.cos(hra))\r\n","\r\n","  # 천정각(Zenith Angle)은 90 - 알파\r\n","  zenith = radians(90) - elevation\r\n","\r\n","  # GHI는 DHI + DNI * cos(천정각)\r\n","  ghi = DHI + DNI *np.cos(zenith)\r\n","\r\n","  return ghi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OYZ1qaX3H070"},"source":["def encoding(data):\r\n","  season_list = [i for i in range(0,24)]\r\n","  for k in season_list:\r\n","    data['Season_' +f'{k}'] = data['season'] == k\r\n","  return data*1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nliyo8xHM10I"},"source":["def not_minus(dataset):\r\n","  for i in range(0, len(dataset.index)):\r\n","    for j in range(0, len(dataset.columns)):\r\n","      K = dataset.iloc[i,j]\r\n","      if K < 0:\r\n","        dataset.iloc[i,j] = 0\r\n","  return dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YS5ODTuh8YeQ"},"source":["dataset = raw_data.copy()\r\n","dataset2 = drop_clms(dataset)\r\n","dataset2.drop(['Hour', 'Minute'], axis =1, inplace=True)\r\n","dataset2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9jaX2IszQCSh"},"source":["dataset2['season'] = dataset2.apply(lambda x: 절기24(x['Date']), axis = 1)\r\n","dataset3 = cos_time(dataset2)\r\n","dataset4 = dataset3[['DHI', 'DNI', 'WS', 'RH', 'T', 'TARGET', 'SH', 'sin_time', 'cos_time','season', 'Time']]\r\n","# dataset5 = dataset4.iloc[n_days:,:-1]\r\n","# goals = pd.DataFrame(dataset4.Goal, index = dataset4.index)\r\n","dataset4"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8yOX-STzBocM"},"source":["dataset5= dataset4.copy()\r\n","\r\n","dataset5['GHI'] = dataset4.apply(lambda x: HRA(x.DHI, x.DNI, x.season, x.Time), axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RpNjhWMrND8z"},"source":["dataset5.iloc[50:51,:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QsFYo0a1NtJ9"},"source":["#dataset6 = dataset5[['DHI', 'DNI', 'WS', 'RH', 'T','SH', 'sin_time', 'cos_time', 'GHI', 'season', 'TARGET']]\r\n","dataset6 = dataset5[['WS', 'RH', 'T','SH', 'sin_time', 'cos_time', 'GHI', 'TARGET']]\r\n","dataset6.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lLyxc0ogc08j"},"source":["# scaler = MinMaxScaler()\r\n","scaler = StandardScaler()\r\n","scaler.fit(dataset6)\r\n","temp_X = pd.DataFrame(scaler.transform(dataset6), columns = dataset6.columns)\r\n","temp_y = pd.DataFrame(dataset6['TARGET'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qfzLMGBy_YUJ"},"source":["## dataset6 가지고 동일하게 to_supervised 함수를 써서 나누면 됩니다.\r\n","### 나머지 변수 합치기, 인코딩은 유진이가 해줄 것..."]},{"cell_type":"code","metadata":{"id":"8zMKRkOh86bm"},"source":["dataset7 = train_to_supervised(temp_X,temp_y, n_days)\r\n","dataset7"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TIzzIDzeDTQR"},"source":["X = dataset7.iloc[:,:-2]\r\n","#X = encoding(X)\r\n","#X.drop('season', axis =1, inplace=True)\r\n","\r\n","y_1 = pd.DataFrame(dataset7.iloc[:,-2])\r\n","y_2 = pd.DataFrame(dataset7.iloc[:,-1])\r\n","X"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mse-YpNROEty"},"source":["# testset은 이미 24절기(season)가 들어있으므로, 약간 다르게 전처리를 해 줘야 함.\r\n","## (season) 구하는 과정이 생략됨.\r\n","## 이하는 testset을 구하는 코드"]},{"cell_type":"code","metadata":{"id":"dVUbVganOw09"},"source":["file_path = '/content/drive/MyDrive/Jupyter/unlimited_power/raw_data/test/' + str(1) + '.csv'\r\n","new_path = '/content/drive/MyDrive/Jupyter/unlimited_power/raw_data/test/adj_test/' + str(1) + '.csv'\r\n","file_name = str(1) + '.csv'\r\n","\r\n","# adj_test에서 가져와야 하므로 new_path에서 불러온다\r\n","temp = pd.read_csv(new_path)\r\n","temp"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XikHh5bPO_oE"},"source":["temp.drop('Unnamed: 0', axis = 1, inplace = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YuosnjSHPHTn"},"source":["testset = temp.copy()\r\n","\r\n","# 24로 저장한 24절기 season으로 이름 바꾸기\r\n","testset.rename(columns = {'24' : 'season'}, inplace = True)\r\n","\r\n","\r\n","# 이 다음은 trainset과 동일한 전처리, season은 이미 구해져 있으므로 구하지 않음\r\n","testset2 = drop_clms(testset)\r\n","testset2.drop(['Hour', 'Minute','Date'], axis=1,inplace=True)\r\n","testset3 = cos_time(testset2)\r\n","testset4 = testset3[['DHI', 'DNI', 'WS', 'RH', 'T', 'TARGET', 'SH', 'sin_time', 'cos_time','season', 'Time']]\r\n","testset4"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QrMcmPqXQg8f"},"source":["testset5 = testset4.copy()\r\n","testset5['GHI'] = testset4.apply(lambda x: HRA(x.DHI, x.DNI, x.season, x.Time), axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TMtkCPWUSNVS"},"source":["testset5.iloc[50:51,:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HNOJX5RASQjT"},"source":["#### testset과 dataset이 같은 모양인지 중간점검\r\n","dataset5.iloc[50:51,:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RyiUU-Y-Sc8y"},"source":["testset6 = testset5[['WS', 'RH', 'T','SH', 'sin_time', 'cos_time', 'GHI', 'TARGET']]\r\n","testset6.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1EtSz9zAd3rq"},"source":["testset6 = pd.DataFrame(scaler.transform(testset6), columns = testset6.columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LumJPLaDENZm"},"source":["testset7 = test_to_supervised(testset6, n_days)\r\n","testset7"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RG0VdrGGGLgE"},"source":["testset9 = testset7.iloc[-48:,:] #season을 다시 붙인다면 testset7->8 근데 여기 이해가 안돼.. 48 뭐임? 하루치?\r\n","testset9"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Im2u9TTwSy7M"},"source":["df_test = []\r\n","\r\n","# 예시 코드\r\n","# 아직 유진이 어떻게 변수 추가할 지 몰라서 to_supervised는 쓰지 않았음.\r\n","\r\n","for i in range(81):\r\n","    file_path = '/content/drive/MyDrive/Jupyter/unlimited_power/raw_data/test/' + str(i) + '.csv'\r\n","    new_path = '/content/drive/MyDrive/Jupyter/unlimited_power/raw_data/test/adj_test/' + str(i) + '.csv'\r\n","    file_name = str(i) + '.csv'\r\n","\r\n","    \r\n","    # adj_test에서 가져와야 하므로 new_path에서 불러온다\r\n","    temp = pd.read_csv(new_path)\r\n","    temp.drop('Unnamed: 0', axis = 1, inplace = True)\r\n","    testset = temp.copy()\r\n","\r\n","    # 24로 저장한 24절기 season으로 이름 바꾸기\r\n","    testset.rename(columns = {'24' : 'season'}, inplace = True)\r\n","\r\n","    # 이 다음은 trainset과 동일한 전처리, season은 이미 구해져 있으므로 구하지 않음\r\n","    testset2 = drop_clms(testset)\r\n","    testset2.drop(['Hour', 'Minute','Date'], axis=1,inplace=True)\r\n","    testset3 = cos_time(testset2)\r\n","    testset4 = testset3[['DHI', 'DNI', 'WS', 'RH', 'T', 'TARGET', 'SH', 'sin_time', 'cos_time','season', 'Time']]\r\n","\r\n","    testset5 = testset4.copy()\r\n","    testset5['GHI'] = testset4.apply(lambda x: HRA(x.DHI, x.DNI, x.season, x.Time), axis=1)\r\n","    testset6 = testset5[['WS', 'RH', 'T','SH', 'sin_time', 'cos_time', 'GHI', 'TARGET']] #'DHI', 'DNI', 'season'\r\n","    testset6 = pd.DataFrame(scaler.transform(testset6), columns=testset6.columns)\r\n","    testset7 = test_to_supervised(testset6, n_days)\r\n","\r\n","#    testset8 = encoding(testset7)\r\n","#    testset8.drop('season', axis = 1, inplace = True)\r\n","    testset9 = testset7.iloc[-48:,:]\r\n","\r\n","    df_test.append(testset9)\r\n","\r\n","X_test = pd.concat(df_test)\r\n","# X_test = X_test.iloc[:, :n_obs]\r\n","X_test "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QivVaEkGK-gR"},"source":["X_train_1, X_valid_1, Y_train_1,  Y_valid_1 = train_test_split(X, y_1, test_size=0.30, random_state=42)\r\n","X_train_2, X_valid_2, Y_train_2,  Y_valid_2 = train_test_split(X, y_2, test_size=0.30, random_state=42)\r\n","\r\n","quantiles = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0DvO2slcLfiH"},"source":["# LGBM 모델을 구축하고 예측까지 하는 함수를 만든다. \r\n","def LGBM(q, X_train, Y_train, X_valid, Y_valid, X_test):\r\n","    \r\n","    # (a) 모델링\r\n","    model = LGBMRegressor(objective='quantile', alpha=q,\r\n","                         n_estimators=10000, bagging_fraction=0.7, learning_rate=0.005, save_binary = True, subsample=0.7, device = 'gpu')          \r\n","    \r\n","        # bagging_fraction : 배깅을 하기위해서 데이터를 랜덤 샘플링하여 학습에 사용한다. 비율은 0 < fraction <= 1 이며 0이 되지 않게 해야한다.\r\n","        # learning_rate : 일반적으로 0.01 ~ 0.1 정도로 맞추고 다른 파라미터를 튜닝한다. 나중에 성능을 더 높일 때 learning rate를 더 줄인다.\r\n","        # n_estimators : 기본값은 100, 1000 정도로 해주는 게 좋고 많을 수록 과적합이 발생한 가능성이 높음.\r\n","        # save_binary = True 넣어주면 더 빨라진다고 함.\r\n","        # https://greatjoy.tistory.com/72\r\n","        \r\n","    model.fit(X_train, Y_train, eval_metric = ['quantile'], eval_set=[(X_valid, Y_valid)], early_stopping_rounds=500, verbose=500)\r\n","\r\n","\r\n","        # verbose : eval metric이 이 숫자만큼의 round가 지난 다음 자동으로 출력된다.\r\n","        # early_stopping_rounds : 이 숫자가 가기 전까지 validation score가 증가하지 않으면 round를 멈춘다. \r\n","\r\n","    # (b) 예측\r\n","    pred = pd.Series(model.predict(X_test).round(2))\r\n","    return pred, model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_GYrgqYqLrO1"},"source":["# Target 예측\r\n","\r\n","def train_data(X_train, Y_train, X_valid, Y_valid, X_test):\r\n","\r\n","    LGBM_models=[]\r\n","    LGBM_actual_pred = pd.DataFrame()\r\n","\r\n","    for q in quantiles:\r\n","        print(q)\r\n","        pred, model = LGBM(q, X_train, Y_train, X_valid, Y_valid, X_test)\r\n","        LGBM_models.append(model)\r\n","        LGBM_actual_pred = pd.concat([LGBM_actual_pred,pred],axis=1)\r\n","\r\n","    LGBM_actual_pred.columns=quantiles\r\n","    \r\n","    return LGBM_models, LGBM_actual_pred"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1kDBEXW8Ltfi"},"source":["tick = time.time()\r\n","\r\n","# Target1\r\n","\r\n","models_1, results_1 = train_data(X_train_1, Y_train_1, X_valid_1, Y_valid_1, X_test)\r\n","results_1.sort_index()[:48]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qlvhd5SwLu0-"},"source":["# Target2\r\n","\r\n","models_2, results_2 = train_data(X_train_2, Y_train_2, X_valid_2, Y_valid_2, X_test)\r\n","tock = time.time()\r\n","results_2.sort_index()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j-hFzqsOLwh9"},"source":["print('소요시간 :', tock-tick)\r\n","\r\n","print(results_1.shape, results_2.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lpyzax_JLydx"},"source":["# 출력\r\n","\r\n","submission.loc[submission.id.str.contains(\"Day7\"), \"q_0.1\":] = results_1.sort_index().values\r\n","submission.loc[submission.id.str.contains(\"Day8\"), \"q_0.1\":] = results_2.sort_index().values\r\n","submission2 = submission.set_index('id')\r\n","submission3 = not_minus(submission2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9YEmJ9IvLy9K"},"source":["submission3.to_csv('submission_standardlize.csv')\r\n","!cp submission_standardlize.csv \"drive/My Drive/\""],"execution_count":null,"outputs":[]}]}